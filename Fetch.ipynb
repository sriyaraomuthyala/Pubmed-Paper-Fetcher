{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26e45483-64a6-4949-8699-2dc15f89fb09",
   "metadata": {},
   "source": [
    "**RESEARCH PAPER FETCHER**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2f084a-431c-43b1-86d5-273074f96f9d",
   "metadata": {},
   "source": [
    "Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba85ce85-dc43-42bd-b5e4-45ac6968de0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytest in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (8.3.3)\n",
      "Collecting poetry (from -r requirements.txt (line 2))\n",
      "  Using cached poetry-2.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (1.5.3)\n",
      "Collecting biopython (from -r requirements.txt (line 4))\n",
      "  Using cached biopython-1.84-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (1.24.4)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from pytest->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from pytest->-r requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from pytest->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from pytest->-r requirements.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: build<2.0.0,>=1.2.1 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from poetry->-r requirements.txt (line 2)) (1.2.2.post1)\n",
      "Collecting cachecontrol<0.15.0,>=0.14.0 (from cachecontrol[filecache]<0.15.0,>=0.14.0->poetry->-r requirements.txt (line 2))\n",
      "  Downloading cachecontrol-0.14.2-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting cleo<3.0.0,>=2.1.0 (from poetry->-r requirements.txt (line 2))\n",
      "  Using cached cleo-2.1.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dulwich<0.23.0,>=0.22.6 (from poetry->-r requirements.txt (line 2))\n",
      "  Using cached dulwich-0.22.7-cp311-cp311-win_amd64.whl.metadata (4.5 kB)\n",
      "Collecting fastjsonschema<3.0.0,>=2.18.0 (from poetry->-r requirements.txt (line 2))\n",
      "  Downloading fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting installer<0.8.0,>=0.7.0 (from poetry->-r requirements.txt (line 2))\n",
      "  Using cached installer-0.7.0-py3-none-any.whl.metadata (936 bytes)\n",
      "Collecting keyring<26.0.0,>=25.1.0 (from poetry->-r requirements.txt (line 2))\n",
      "  Using cached keyring-25.6.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting packaging (from pytest->-r requirements.txt (line 1))\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pkginfo<2.0,>=1.12 (from poetry->-r requirements.txt (line 2))\n",
      "  Using cached pkginfo-1.12.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.0.0 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from poetry->-r requirements.txt (line 2)) (3.10.0)\n",
      "Collecting poetry-core==2.0.0 (from poetry->-r requirements.txt (line 2))\n",
      "  Using cached poetry_core-2.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: pyproject-hooks<2.0.0,>=1.0.0 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from poetry->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.26 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from poetry->-r requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from poetry->-r requirements.txt (line 2)) (1.0.0)\n",
      "Collecting shellingham<2.0,>=1.5 (from poetry->-r requirements.txt (line 2))\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting tomlkit<1.0.0,>=0.11.4 (from poetry->-r requirements.txt (line 2))\n",
      "  Using cached tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting trove-classifiers>=2022.5.19 (from poetry->-r requirements.txt (line 2))\n",
      "  Downloading trove_classifiers-2025.1.7.14-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting virtualenv<21.0.0,>=20.26.6 (from poetry->-r requirements.txt (line 2))\n",
      "  Using cached virtualenv-20.28.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2023.3.post1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=0.5.2 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from cachecontrol<0.15.0,>=0.14.0->cachecontrol[filecache]<0.15.0,>=0.14.0->poetry->-r requirements.txt (line 2)) (1.0.3)\n",
      "Requirement already satisfied: filelock>=3.8.0 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from cachecontrol[filecache]<0.15.0,>=0.14.0->poetry->-r requirements.txt (line 2)) (3.13.1)\n",
      "Collecting crashtest<0.5.0,>=0.4.1 (from cleo<3.0.0,>=2.1.0->poetry->-r requirements.txt (line 2))\n",
      "  Using cached crashtest-0.4.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.0.0 (from cleo<3.0.0,>=2.1.0->poetry->-r requirements.txt (line 2))\n",
      "  Using cached rapidfuzz-3.11.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: urllib3>=1.25 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from dulwich<0.23.0,>=0.22.6->poetry->-r requirements.txt (line 2)) (2.0.7)\n",
      "Requirement already satisfied: pywin32-ctypes>=0.2.0 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from keyring<26.0.0,>=25.1.0->poetry->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: importlib_metadata>=4.11.4 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from keyring<26.0.0,>=25.1.0->poetry->-r requirements.txt (line 2)) (7.0.1)\n",
      "Requirement already satisfied: jaraco.classes in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from keyring<26.0.0,>=25.1.0->poetry->-r requirements.txt (line 2)) (3.2.1)\n",
      "Collecting jaraco.functools (from keyring<26.0.0,>=25.1.0->poetry->-r requirements.txt (line 2))\n",
      "  Using cached jaraco.functools-4.1.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jaraco.context (from keyring<26.0.0,>=25.1.0->poetry->-r requirements.txt (line 2))\n",
      "  Using cached jaraco.context-6.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.26->poetry->-r requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.26->poetry->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.26->poetry->-r requirements.txt (line 2)) (2024.2.2)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv<21.0.0,>=20.26.6->poetry->-r requirements.txt (line 2))\n",
      "  Using cached distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from importlib_metadata>=4.11.4->keyring<26.0.0,>=25.1.0->poetry->-r requirements.txt (line 2)) (3.17.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\sriya\\anaconda3\\lib\\site-packages (from jaraco.classes->keyring<26.0.0,>=25.1.0->poetry->-r requirements.txt (line 2)) (10.1.0)\n",
      "Collecting backports.tarfile (from jaraco.context->keyring<26.0.0,>=25.1.0->poetry->-r requirements.txt (line 2))\n",
      "  Using cached backports.tarfile-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Using cached poetry-2.0.0-py3-none-any.whl (253 kB)\n",
      "Using cached poetry_core-2.0.0-py3-none-any.whl (544 kB)\n",
      "Using cached biopython-1.84-cp311-cp311-win_amd64.whl (2.8 MB)\n",
      "Downloading cachecontrol-0.14.2-py3-none-any.whl (21 kB)\n",
      "Using cached cleo-2.1.0-py3-none-any.whl (78 kB)\n",
      "Using cached dulwich-0.22.7-cp311-cp311-win_amd64.whl (599 kB)\n",
      "Downloading fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
      "Using cached installer-0.7.0-py3-none-any.whl (453 kB)\n",
      "Using cached keyring-25.6.0-py3-none-any.whl (39 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pkginfo-1.12.0-py3-none-any.whl (32 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading trove_classifiers-2025.1.7.14-py3-none-any.whl (13 kB)\n",
      "Using cached virtualenv-20.28.1-py3-none-any.whl (4.3 MB)\n",
      "Using cached crashtest-0.4.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
      "Using cached rapidfuzz-3.11.0-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "Using cached jaraco.context-6.0.1-py3-none-any.whl (6.8 kB)\n",
      "Using cached jaraco.functools-4.1.0-py3-none-any.whl (10 kB)\n",
      "Using cached backports.tarfile-1.2.0-py3-none-any.whl (30 kB)\n",
      "Installing collected packages: trove-classifiers, fastjsonschema, distlib, virtualenv, tomlkit, shellingham, rapidfuzz, poetry-core, pkginfo, packaging, jaraco.functools, installer, dulwich, crashtest, biopython, backports.tarfile, jaraco.context, cleo, cachecontrol, keyring, poetry\n",
      "  Attempting uninstall: fastjsonschema\n",
      "    Found existing installation: fastjsonschema 2.16.2\n",
      "    Uninstalling fastjsonschema-2.16.2:\n",
      "      Successfully uninstalled fastjsonschema-2.16.2\n",
      "  Attempting uninstall: tomlkit\n",
      "    Found existing installation: tomlkit 0.11.1\n",
      "    Uninstalling tomlkit-0.11.1:\n",
      "      Successfully uninstalled tomlkit-0.11.1\n",
      "  Attempting uninstall: pkginfo\n",
      "    Found existing installation: pkginfo 1.9.6\n",
      "    Uninstalling pkginfo-1.9.6:\n",
      "      Successfully uninstalled pkginfo-1.9.6\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.2\n",
      "    Uninstalling packaging-23.2:\n",
      "      Successfully uninstalled packaging-23.2\n",
      "  Attempting uninstall: keyring\n",
      "    Found existing installation: keyring 23.13.1\n",
      "    Uninstalling keyring-23.13.1:\n",
      "      Successfully uninstalled keyring-23.13.1\n",
      "Successfully installed backports.tarfile-1.2.0 biopython-1.84 cachecontrol-0.14.2 cleo-2.1.0 crashtest-0.4.1 distlib-0.3.9 dulwich-0.22.7 fastjsonschema-2.21.1 installer-0.7.0 jaraco.context-6.0.1 jaraco.functools-4.1.0 keyring-25.6.0 packaging-24.2 pkginfo-1.12.0 poetry-2.0.0 poetry-core-2.0.0 rapidfuzz-3.11.0 shellingham-1.5.4 tomlkit-0.13.2 trove-classifiers-2025.1.7.14 virtualenv-20.28.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-cloud-auth 0.1.4 requires pydantic<2.0, but you have pydantic 2.9.2 which is incompatible.\n",
      "anaconda-cloud-auth 0.1.4 requires semver<3, but you have semver 3.0.2 which is incompatible.\n",
      "langchain-core 0.1.52 requires packaging<24.0,>=23.2, but you have packaging 24.2 which is incompatible.\n",
      "streamlit 1.30.0 requires packaging<24,>=16.8, but you have packaging 24.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08267428-73a6-4a85-81e7-463d1dbc57c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "from Bio import Entrez\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d59dabd-0886-4899-b4dd-236d39e95743",
   "metadata": {},
   "source": [
    "Details required to access the data from PubMed API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00057815-7b3d-4c77-be4b-ad97e77e0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = \"your_email@example.com\"  # Replace with your email for API acces\n",
    "PUBMED_SEARCH_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "PUBMED_SUMMARY_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dc54b0-76ef-458e-acec-712929c82852",
   "metadata": {},
   "source": [
    "Defining helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c308cd-fbdf-4e50-8c94-b7e0e272f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that searches the query from Pubmed and retrieves 100 results\n",
    "def fetch_pubmed_ids(query: str, max_results: int = 100) -> List[str]:\n",
    "    params = {\n",
    "        \"db\": \"pubmed\",\n",
    "        \"term\": query,\n",
    "        \"retmax\": max_results,\n",
    "        \"retmode\": \"json\"\n",
    "    }\n",
    "    response = requests.get(PUBMED_SEARCH_URL, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json().get(\"esearchresult\", {}).get(\"idlist\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f6a421f-1db4-4111-8bb5-99c874c83332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching summaries of each paper from the papers list\n",
    "def fetch_paper_summaries(pubmed_ids: List[str]) -> List[Dict[str, str]]:\n",
    "    params = {\n",
    "        \"db\": \"pubmed\",\n",
    "        \"id\": \",\".join(pubmed_ids),\n",
    "        \"retmode\": \"json\"\n",
    "    }\n",
    "    response = requests.get(PUBMED_SUMMARY_URL, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json().get(\"result\", {})\n",
    "    return [\n",
    "        {\n",
    "            \"PubmedID\": paper_id,\n",
    "            \"Title\": data.get(paper_id, {}).get(\"title\", \"\"),\n",
    "            \"Publication Date\": data.get(paper_id, {}).get(\"pubdate\", \"\")\n",
    "        }\n",
    "        for paper_id in pubmed_ids\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2edac2f6-80f0-4cfe-b65e-4a43c1f06b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching Names of authors and email listed in each research paper\n",
    "def fetch_paper_authors_batch(pubmed_ids: List[str]) -> Dict[str, List[Dict[str, str]]]:\n",
    "    result = {}\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=\",\".join(pubmed_ids), rettype=\"xml\", retmode=\"text\")\n",
    "    records = handle.read()\n",
    "    root = ET.fromstring(records)\n",
    "\n",
    "    for article in root.findall(\".//PubmedArticle\"):\n",
    "        pmid = article.find(\".//PMID\").text\n",
    "        authors_info = []\n",
    "        for author in article.findall(\".//AuthorList/Author\"):\n",
    "            last_name = author.find(\"LastName\")\n",
    "            fore_name = author.find(\"ForeName\")\n",
    "            if last_name is None or fore_name is None:\n",
    "                continue\n",
    "            author_name = f\"{last_name.text} {fore_name.text}\"\n",
    "            affiliation = author.find(\"AffiliationInfo/Affiliation\")\n",
    "            email = None\n",
    "            if affiliation is not None:\n",
    "                affiliation = affiliation.text\n",
    "                if \"@\" in affiliation:\n",
    "                    email = affiliation.split()[-1]\n",
    "            authors_info.append({\n",
    "                \"Author\": author_name,\n",
    "                \"Affiliation\": affiliation or \"N/A\",\n",
    "                \"Email\": email\n",
    "            })\n",
    "        result[pmid] = authors_info\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c26ad26-5e96-4b58-b37b-3d1f471b5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to fetch and save data\n",
    "def main(query, output_folder=None, debug=False):\n",
    "    if debug:\n",
    "        print(f\"Fetching papers for query: {query}\")\n",
    "\n",
    "    # Fetch PubMed IDs\n",
    "    pubmed_ids = fetch_pubmed_ids(query)\n",
    "\n",
    "    # Use multithreading to fetch summaries and authors concurrently\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        summaries_future = executor.submit(fetch_paper_summaries, pubmed_ids)\n",
    "        authors_future = executor.submit(fetch_paper_authors_batch, pubmed_ids)\n",
    "        summaries = summaries_future.result()\n",
    "        authors_batch = authors_future.result()\n",
    "\n",
    "    # Process the results\n",
    "    results = []\n",
    "    for summary in summaries:\n",
    "        pubmed_id = summary[\"PubmedID\"]\n",
    "        authors = authors_batch.get(pubmed_id, [])\n",
    "        non_academic_authors = [a[\"Author\"] for a in authors if \"university\" not in (a[\"Affiliation\"] or \"\").lower()]\n",
    "        affiliations = {a[\"Affiliation\"] for a in authors}\n",
    "\n",
    "        summary.update({\n",
    "            \"Non-academic Author(s)\": \", \".join(non_academic_authors),\n",
    "            \"Affiliation(s)\": \", \".join(affiliations),\n",
    "            \"Author Email\": next((a[\"Email\"] for a in authors if a[\"Email\"]), \"N/A\")\n",
    "        })\n",
    "        results.append(summary)\n",
    "\n",
    "    # Determine the output folder\n",
    "    if output_folder and os.path.isdir(output_folder):\n",
    "        output_folder = output_folder\n",
    "    else:\n",
    "        sanitized_query = query.replace(\" \", \"_\")\n",
    "        output_folder = os.path.join(\".\", sanitized_query)\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Save the CSV using the query name\n",
    "    full_path = save_to_csv_with_query_name(results, query, output_folder)\n",
    "    \n",
    "    # Print completion message\n",
    "    print(f\"Results saved to: {full_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a9320ea-2d83-4032-9207-5b4161a4d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save to CSV\n",
    "def save_to_csv_with_query_name(papers, query, output_folder):\n",
    "    sanitized_query = query.replace(\" \", \"_\")\n",
    "    filename = f\"{sanitized_query}.csv\"\n",
    "    full_path = os.path.join(output_folder, filename)\n",
    "    df = pd.DataFrame(papers)\n",
    "    df.to_csv(full_path, index=False)\n",
    "    return full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "777f2eae-9f12-41a9-a380-f87d003aff6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: .\\Cancer_Therapy\\Cancer_Therapy.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "query = \"Cancer Therapy\"\n",
    "\n",
    "# Run the main function\n",
    "main(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a358bf-8973-4faf-9439-0bdc7ffe94b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
